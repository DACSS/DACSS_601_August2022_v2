{
  "hash": "d2d87c10c71f9c6d6940a810804597fa",
  "result": {
    "markdown": "---\ntitle: \"Challenge 3\"\nauthor: \"Miranda Manka\"\ndescription: \"Tidy data: pivoting\"\ndate: \"08/18/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_3\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1.  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2.  identify what needs to be done to tidy the current data\n3.  anticipate the shape of pivoted data\n4.  pivot the data into tidy format using `pivot_longer`\n\n## Read in data\n\n\n::: {.cell}\n\n```{.r .cell-code}\norganic_eggs = read_excel(\"_data/organiceggpoultry.xls\",\n  sheet = \"Data\", \n  range = \"B6:F125\", \n  col_names = c(\"date\", \"extralarge_dozen\", \"extralarge_halfdozen\", \n     \"large_dozen\", \"large_halfdozen\"))\n\norganic_eggs = organic_eggs %>% \n  mutate(date = str_remove(date, \" /1\"))\n\norganic_eggs = organic_eggs %>% \n  separate(date, into = c(\"month\", \"year\"), sep = \" \") %>% \n  fill(year)\n\ndim(organic_eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 120   6\n```\n:::\n\n```{.r .cell-code}\nhead(organic_eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 6\n  month    year  extralarge_dozen extralarge_halfdozen large_dozen large_halfd…¹\n  <chr>    <chr>            <dbl>                <dbl>       <dbl>         <dbl>\n1 Jan      2004              230                  132         230           126 \n2 February 2004              230                  134.        226.          128.\n3 March    2004              230                  137         225           131 \n4 April    2004              234.                 137         225           131 \n5 May      2004              236                  137         225           131 \n6 June     2004              241                  137         231.          134.\n# … with abbreviated variable name ¹​large_halfdozen\n```\n:::\n:::\n\n\n### Briefly describe the data\n\nAfter reading in the data and doing some cleaning, the dataset is ready to move on to the next step. This is a dataset about organic egg costs over time for different sizes and quantities of eggs (both large and extra large, dozen and half dozen eggs, for each month from 2004 to 2013), with 120 rows and 6 columns. The 6 columns are month, year, extralarge_dozen, extralarge_halfdozen, large_dozen, and large_halfdozen. As explained in class, these names make it easier to pivot data in the future (think about what the final pivoted data should look like and name accordingly). This data needs to be pivoted because right now each row does not  represent a unique observation (for example Jan 2004 has prices for 4 different types of eggs).\n\n## Find current data dimensions & Anticipate the end result\n\nThis dataset has n = 120 rows and k = 6 variables (the dimensions were found in the code above). Since 2 of the variables are used to identify a case (month and year), k - 2 = 6 - 2 = 4 variables will be pivoted into a longer format. Therefore, there should be n * (k - 2) = 120 * (6 - 2) = 120 * 4 = 480 rows in the pivoted dataframe.\n\n### Pivot the data & Describe the final dimensions\n\n\n::: {.cell}\n\n```{.r .cell-code}\norganic_eggs = organic_eggs %>% \n  pivot_longer(cols = contains(\"dozen\"), names_to = c(\"size\", \"quantity\"), \n     names_sep=\"_\", values_to = \"price\")\n\ndim(organic_eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 480   5\n```\n:::\n:::\n\n\nAs expected, the final dataset has 480 rows. Each row (case) is a unique observation that contains the month, year, size, quantity, and price. The data has been successfully pivoted so that further analysis can take place. The data is now tidy because each row now contains a single observation/case (month and year information, ttype and quantity, and price) instead of what the dataset started at (date and 4 different columns for the different size and quantities). The naming conventions and thinking about what the final dataset will be, helped to pivot smoothly to better rows and columns.\n",
    "supporting": [
      "challenge3_MirandaManka_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
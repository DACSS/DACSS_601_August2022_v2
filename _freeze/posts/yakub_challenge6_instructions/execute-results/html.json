{
  "hash": "6ed49648d18a097d3a36d436aa79adfa",
  "result": {
    "markdown": "---\ntitle: \"Challenge 6 Instructions\"\nauthor: \"Yakub Rabiutheen\"\ndescription: \"Visualizing Time and Relationships\"\ndate: \"09/01/2022\"\nformat:\n  html:\n    toc: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_6\n  - hotel_bookings\n  - air_bnb\n  - fed_rate\n  - debt\n  - usa_hh\n  - abc_poll\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readxl)\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1)  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2)  tidy data (as needed, including sanity checks)\n3)  mutate variables as needed (including sanity checks)\n4)  create at least one graph including time (evolution)\n   - try to make them \"publication\" ready (optional)\n   - Explain why you choose the specific graph type\n5)  Create at least one graph depicting part-whole or flow relationships\n   - try to make them \"publication\" ready (optional)\n   - Explain why you choose the specific graph type\n\n[R Graph Gallery](https://r-graph-gallery.com/) is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code.\n\n(be sure to only include the category tags for the data you use!)\n\n## Read in data\n\nRead in one (or more) of the following datasets, using the correct R package and command.\n\n  - debt  ⭐\n  - fed_rate ⭐⭐\n  - abc_poll ⭐⭐⭐\n  - usa_hh ⭐⭐⭐\n  - hotel_bookings ⭐⭐⭐⭐\n  - air_bnb  ⭐⭐⭐⭐⭐\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt <- read_excel('_data/debt_in_trillions.xlsx')\n```\n:::\n\n\n### Briefly describe the data\n\n## Tidy Data (as needed)\n\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\nLooking at the head of Data first before doing anything.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(debt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n  `Year and Quarter` Mortgage `HE Revolving` Auto …¹ Credi…² Stude…³ Other Total\n  <chr>                 <dbl>          <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl>\n1 03:Q1                  4.94          0.242   0.641   0.688   0.241 0.478  7.23\n2 03:Q2                  5.08          0.26    0.622   0.693   0.243 0.486  7.38\n3 03:Q3                  5.18          0.269   0.684   0.693   0.249 0.477  7.56\n4 03:Q4                  5.66          0.302   0.704   0.698   0.253 0.449  8.07\n5 04:Q1                  5.84          0.328   0.72    0.695   0.260 0.446  8.29\n6 04:Q2                  5.97          0.367   0.743   0.697   0.263 0.423  8.46\n# … with abbreviated variable names ¹​`Auto Loan`, ²​`Credit Card`,\n#   ³​`Student Loan`\n```\n:::\n:::\n\n\nAre there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\n\nDocument your work here.\n\n\nThe Year and Quarter Column is currently not useful to me the way it currently is.  After doing some research, I found that there is a package called lubridate that helps clean up Dates in R. There is a function called parse_date_time which allows me to turn the 'Year and Quarter' column into usable dates.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\ndebt_clean <-debt %>%\n  mutate(date = parse_date_time(`Year and Quarter`, \n                           orders=\"yq\"))\n```\n:::\n\n\n\nAs Shown below the dates look much cleaner.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_clean$date\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"2003-01-01 UTC\" \"2003-04-01 UTC\" \"2003-07-01 UTC\" \"2003-10-01 UTC\"\n [5] \"2004-01-01 UTC\" \"2004-04-01 UTC\" \"2004-07-01 UTC\" \"2004-10-01 UTC\"\n [9] \"2005-01-01 UTC\" \"2005-04-01 UTC\" \"2005-07-01 UTC\" \"2005-10-01 UTC\"\n[13] \"2006-01-01 UTC\" \"2006-04-01 UTC\" \"2006-07-01 UTC\" \"2006-10-01 UTC\"\n[17] \"2007-01-01 UTC\" \"2007-04-01 UTC\" \"2007-07-01 UTC\" \"2007-10-01 UTC\"\n[21] \"2008-01-01 UTC\" \"2008-04-01 UTC\" \"2008-07-01 UTC\" \"2008-10-01 UTC\"\n[25] \"2009-01-01 UTC\" \"2009-04-01 UTC\" \"2009-07-01 UTC\" \"2009-10-01 UTC\"\n[29] \"2010-01-01 UTC\" \"2010-04-01 UTC\" \"2010-07-01 UTC\" \"2010-10-01 UTC\"\n[33] \"2011-01-01 UTC\" \"2011-04-01 UTC\" \"2011-07-01 UTC\" \"2011-10-01 UTC\"\n[37] \"2012-01-01 UTC\" \"2012-04-01 UTC\" \"2012-07-01 UTC\" \"2012-10-01 UTC\"\n[41] \"2013-01-01 UTC\" \"2013-04-01 UTC\" \"2013-07-01 UTC\" \"2013-10-01 UTC\"\n[45] \"2014-01-01 UTC\" \"2014-04-01 UTC\" \"2014-07-01 UTC\" \"2014-10-01 UTC\"\n[49] \"2015-01-01 UTC\" \"2015-04-01 UTC\" \"2015-07-01 UTC\" \"2015-10-01 UTC\"\n[53] \"2016-01-01 UTC\" \"2016-04-01 UTC\" \"2016-07-01 UTC\" \"2016-10-01 UTC\"\n[57] \"2017-01-01 UTC\" \"2017-04-01 UTC\" \"2017-07-01 UTC\" \"2017-10-01 UTC\"\n[61] \"2018-01-01 UTC\" \"2018-04-01 UTC\" \"2018-07-01 UTC\" \"2018-10-01 UTC\"\n[65] \"2019-01-01 UTC\" \"2019-04-01 UTC\" \"2019-07-01 UTC\" \"2019-10-01 UTC\"\n[69] \"2020-01-01 UTC\" \"2020-04-01 UTC\" \"2020-07-01 UTC\" \"2020-10-01 UTC\"\n[73] \"2021-01-01 UTC\" \"2021-04-01 UTC\"\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(debt_clean, aes(x=date, y=Mortgage)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](yakub_challenge6_instructions_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nI filtered the Dates as I am interested in looking at Metrics from the Finanical Crisis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_clean %>% \n  filter(date< as.POSIXct(\"2010-01-01 01:00:00\", tz=\"UTC\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 × 9\n   `Year and Quarter` Mortgage HE Revolvin…¹ Auto …² Credi…³ Stude…⁴ Other Total\n   <chr>                 <dbl>         <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl>\n 1 03:Q1                  4.94         0.242   0.641   0.688   0.241 0.478  7.23\n 2 03:Q2                  5.08         0.26    0.622   0.693   0.243 0.486  7.38\n 3 03:Q3                  5.18         0.269   0.684   0.693   0.249 0.477  7.56\n 4 03:Q4                  5.66         0.302   0.704   0.698   0.253 0.449  8.07\n 5 04:Q1                  5.84         0.328   0.72    0.695   0.260 0.446  8.29\n 6 04:Q2                  5.97         0.367   0.743   0.697   0.263 0.423  8.46\n 7 04:Q3                  6.21         0.426   0.751   0.706   0.33  0.41   8.83\n 8 04:Q4                  6.36         0.468   0.728   0.717   0.346 0.423  9.04\n 9 05:Q1                  6.51         0.502   0.725   0.71    0.364 0.394  9.21\n10 05:Q2                  6.70         0.528   0.774   0.717   0.374 0.402  9.49\n# … with 19 more rows, 1 more variable: date <dttm>, and abbreviated variable\n#   names ¹​`HE Revolving`, ²​`Auto Loan`, ³​`Credit Card`, ⁴​`Student Loan`\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n```\n:::\n:::\n\n\nOne thing that I am interested in looking at is the rates of Mortgage Debt and what levels it had especially during the financial crisis. As shown below the Mortgage Debt is limited to the Financial Crisis Years is indeed high but not as high as it was in 2020.\n\n## Time Dependent Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_clean %>% \n  filter(date< as.POSIXct(\"2010-01-01 01:00:00\", tz=\"UTC\")) %>%\n  ggplot(aes(x=date, y=Mortgage)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](yakub_challenge6_instructions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n  \n\n\n## Visualizing Part-Whole Relationships\n\nWhat if I Compare it to other Debts during the Financial Crisis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_clean<-debt_clean%>%\n  pivot_longer(cols = Mortgage:Other,\n               names_to = \"Loan\", \n               values_to = \"total\")%>%\n  select(-Total)%>%\n  mutate(Loan = as.factor(Loan))\n```\n:::\n\n\n\n\n\nAs graphed below, it seems that  Mortgage debt was the greatest amount of Debt during the Financial Crisis .\n\n::: {.cell}\n\n```{.r .cell-code}\ndebt_clean %>% \n  filter(date< as.POSIXct(\"2010-01-01 01:00:00\", tz=\"UTC\")) %>%\n  ggplot(aes(x=date, y=total, fill=Loan)) +\n  geom_bar(position=\"stack\", stat=\"identity\") +\n  scale_y_continuous(labels = scales::label_number(suffix = \" Trillion\"))+\n  theme(legend.position = \"top\") +\n  guides(fill = guide_legend(nrow = 1))\n```\n\n::: {.cell-output-display}\n![](yakub_challenge6_instructions_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "yakub_challenge6_instructions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
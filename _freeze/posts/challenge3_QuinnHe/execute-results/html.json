{
  "hash": "273c284bb28b2a9316d4b6801f5de1cf",
  "result": {
    "markdown": "---\ntitle: \"Challenge 3\"\nauthor: \"Quinn He\"\ndesription: \"Tidy Data: Pivoting\"\ndate: \"08/19/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_3\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Note\n\nGo to the \"Eggs\" label if you don't want to see me fumble through a harder data set.\n\n## Read in data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhousehold <-read_excel(\"_data/USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\", \n                skip = 4)\n\nhousehold\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 383 × 16\n   ...1      ...2  Total Under…¹ $15,0…² $25,0…³ $35,0…⁴ $50,0…⁵ $75,0…⁶ $100,…⁷\n   <chr>     <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 ALL RACES <NA>     NA    NA      NA      NA      NA      NA      NA      NA  \n 2 2019      1284…   100     9.1     8       8.3    11.7    16.5    12.3    15.5\n 3 2018      1285…   100    10.1     8.8     8.7    12      17      12.5    15  \n 4 2017 2    1276…   100    10       9.1     9.2    12      16.4    12.4    14.7\n 5 2017      1275…   100    10.1     9.1     9.2    11.9    16.3    12.6    14.8\n 6 2016      1262…   100    10.4     9       9.2    12.3    16.7    12.2    15  \n 7 2015      1258…   100    10.6    10       9.6    12.1    16.1    12.4    14.9\n 8 2014      1245…   100    11.4    10.5     9.6    12.6    16.4    12.1    14  \n 9 2013 3    1239…   100    11.4    10.3     9.5    12.5    16.8    12      13.9\n10 2013 4    1229…   100    11.3    10.4     9.7    13.1    17      12.5    13.6\n# … with 373 more rows, 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Estimate...13 <dbl>,\n#   `Margin of error1 (±)...14` <dbl>, Estimate...15 <chr>,\n#   `Margin of error1 (±)...16` <chr>, and abbreviated variable names\n#   ¹​`Under $15,000`, ²​`$15,000\\r\\nto\\r\\n$24,999`, ³​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁴​`$35,000\\r\\nto\\r\\n$49,999`, ⁵​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁶​`$75,000\\r\\nto\\r\\n$99,999`, ⁷​`$100,000\\r\\nto\\r\\n$149,999`\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n```\n:::\n:::\n\n\n### Briefly describe the data\n\nThis is a data set that contains household income by race for homeowners from 1967 to 2019. The data set is a mess with the first column containing the years listed in descending order followed by the next race in the data set. Also, the columns are listed so poorly that I had to skip some in the read-in section. One thing I notice just by combing through the data set, Asian Americans have a much higher number of people making over \\$200,000 in household income, but this excludes Asian Pacific Islanders. Notes at the bottom also have to be removed. Before I can really see any trends in the data, I need to clean it and organize it. Right now we do not have tidy data!\n\nBelow, the column names do not make any sense and it is clearly not tidy. By changing some of the names, I hope to make it easier to manipulate later on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(household)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"...1\"                       \"...2\"                      \n [3] \"Total\"                      \"Under $15,000\"             \n [5] \"$15,000\\r\\nto\\r\\n$24,999\"   \"$25,000\\r\\nto\\r\\n$34,999\"  \n [7] \"$35,000\\r\\nto\\r\\n$49,999\"   \"$50,000\\r\\nto\\r\\n$74,999\"  \n [9] \"$75,000\\r\\nto\\r\\n$99,999\"   \"$100,000\\r\\nto\\r\\n$149,999\"\n[11] \"$150,000\\r\\nto\\r\\n$199,999\" \"$200,000 and over\"         \n[13] \"Estimate...13\"              \"Margin of error1 (±)...14\" \n[15] \"Estimate...15\"              \"Margin of error1 (±)...16\" \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhousehold <- household %>% \n  rename(\"year\" = \"...1\", \"num_thousands\" = \"...2\", \"median_income\" = \"Estimate...13\", \"mean_income\" = \"Estimate...15\")\n```\n:::\n\n\nOkay, so I changed some of the names so it's a little neater. Now, at least the columns, are easier to read, but there is still the problem of the \"year\" column. It contains all the races, as well as the years in the data set so it's much more difficult to look at individual races. There are also random numbers at the end of some of the years.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhousehold <- household %>% \n  mutate(year = str_remove(year, \" [0:28]\"))\n\nhousehold\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 383 × 16\n   year    num_t…¹ Total Under…² $15,0…³ $25,0…⁴ $35,0…⁵ $50,0…⁶ $75,0…⁷ $100,…⁸\n   <chr>   <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 ALL RA… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 2 2019    128451    100     9.1     8       8.3    11.7    16.5    12.3    15.5\n 3 2018    128579    100    10.1     8.8     8.7    12      17      12.5    15  \n 4 2017    127669    100    10       9.1     9.2    12      16.4    12.4    14.7\n 5 2017    127586    100    10.1     9.1     9.2    11.9    16.3    12.6    14.8\n 6 2016    126224    100    10.4     9       9.2    12.3    16.7    12.2    15  \n 7 2015    125819    100    10.6    10       9.6    12.1    16.1    12.4    14.9\n 8 2014    124587    100    11.4    10.5     9.6    12.6    16.4    12.1    14  \n 9 2013 3  123931    100    11.4    10.3     9.5    12.5    16.8    12      13.9\n10 2013 4  122952    100    11.3    10.4     9.7    13.1    17      12.5    13.6\n# … with 373 more rows, 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, median_income <dbl>,\n#   `Margin of error1 (±)...14` <dbl>, mean_income <chr>,\n#   `Margin of error1 (±)...16` <chr>, and abbreviated variable names\n#   ¹​num_thousands, ²​`Under $15,000`, ³​`$15,000\\r\\nto\\r\\n$24,999`,\n#   ⁴​`$25,000\\r\\nto\\r\\n$34,999`, ⁵​`$35,000\\r\\nto\\r\\n$49,999`,\n#   ⁶​`$50,000\\r\\nto\\r\\n$74,999`, ⁷​`$75,000\\r\\nto\\r\\n$99,999`, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n```\n:::\n:::\n\n\nIn the above function, I try to remove the excess numbers after the years in the \"years\" column, but I cannot figure out why the numbers still remain. It's necessary I remove them in the future, but for now I will push on.\n\n### Sanity Check\n\nHere are our dimensions for the data before it's pivoted\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(household)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 383  16\n```\n:::\n:::\n\n\n### Challenge: Pivot the Chosen Data\n\nDocument your work here. What will a new \"case\" be once you have pivoted the data? How does it meet requirements for tidy data?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhousehold2 <- pivot_longer(household, cols = 4:12,\n                          names_to = \"income\",\n                          values_to = \"count\")\n\nhousehold2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,447 × 9\n   year      num_thousands Total median_i…¹ Margi…² mean_…³ Margi…⁴ income count\n   <chr>     <chr>         <dbl>      <dbl>   <dbl> <chr>   <chr>   <chr>  <dbl>\n 1 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"Unde…  NA  \n 2 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$15,…  NA  \n 3 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$25,…  NA  \n 4 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$35,…  NA  \n 5 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$50,…  NA  \n 6 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$75,…  NA  \n 7 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$100…  NA  \n 8 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$150…  NA  \n 9 ALL RACES <NA>             NA         NA      NA <NA>    <NA>    \"$200…  NA  \n10 2019      128451          100      68703     904 98088   1042    \"Unde…   9.1\n# … with 3,437 more rows, and abbreviated variable names ¹​median_income,\n#   ²​`Margin of error1 (±)...14`, ³​mean_income, ⁴​`Margin of error1 (±)...16`\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nWell, that turned out horribly. I'm going to leave that mistake here and move on to try and fix that. Clearly, the data is anything but tidy.\n\nLet's try that again below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhousehold3 <- pivot_longer(household, 4:12, names_to = \"income_brackets\", values_to = \"count\")\n```\n:::\n\n\n### Switch to Eggs Data Set\n\nI'm going to switch data sets because I think I am a little over my head in this data frame, from here on out I will be working with \"Eggs\". Below I will run through the assignment quicker than above to save you some already spent time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggs <- read_excel(\"_data/organiceggpoultry.xls\",\n                   sheet = \"Data\",\n                   skip = 4,\n                   range =cell_limits(c(6,2),c(NA,6)),\n                  col_names = c(\"date\", \"xldozen\", \"xlhalf_dozen\", \"large_dozen\", \"large_half_dozen\"))\n\neggs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 120 × 5\n   date      xldozen xlhalf_dozen large_dozen large_half_dozen\n   <chr>       <dbl>        <dbl>       <dbl>            <dbl>\n 1 Jan 2004     230          132         230              126 \n 2 February     230          134.        226.             128.\n 3 March        230          137         225              131 \n 4 April        234.         137         225              131 \n 5 May          236          137         225              131 \n 6 June         241          137         231.             134.\n 7 July         241          137         234.             134.\n 8 August       241          137         234.             134.\n 9 September    241          136.        234.             130.\n10 October      241          136.        234.             128.\n# … with 110 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nAbove I read in the data set as an excel file. I had to look at the solutions sheet to learn how to read in the data. The only trouble I had was figuring out the \"range\" parameter of the function. That one I just had to copy in because I was getting an error without it, but I understand that this tells R which cells to read.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggs %>% \n  select(\"date\")  %>% \n  distinct()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 22 × 1\n   date     \n   <chr>    \n 1 Jan 2004 \n 2 February \n 3 March    \n 4 April    \n 5 May      \n 6 June     \n 7 July     \n 8 August   \n 9 September\n10 October  \n# … with 12 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nNow we still have the issue of notes in the names of our months. This is most evident with \"Jan...\", but the \" /1\" in February needs to go. This needs to be removed to make analysis later on a bit easier to look at.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggs <- eggs %>% \n  mutate(date = str_remove(date, \" /1\"))\n```\n:::\n\n\nNext, the January columns need to be dealt with so below I will remove the years in the \"Jan\" column with the separate and fill function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggs <- eggs %>% \n  separate(date, c(\"month\", \"year\"), convert = TRUE) %>% \n  fill(\"year\")\n  \n\neggs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 120 × 6\n   month      year xldozen xlhalf_dozen large_dozen large_half_dozen\n   <chr>     <int>   <dbl>        <dbl>       <dbl>            <dbl>\n 1 Jan        2004    230          132         230              126 \n 2 February   2004    230          134.        226.             128.\n 3 March      2004    230          137         225              131 \n 4 April      2004    234.         137         225              131 \n 5 May        2004    236          137         225              131 \n 6 June       2004    241          137         231.             134.\n 7 July       2004    241          137         234.             134.\n 8 August     2004    241          137         234.             134.\n 9 September  2004    241          136.        234.             130.\n10 October    2004    241          136.        234.             128.\n# … with 110 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nThere we go. Clean, easy to use data. You can see as the years progress, the price of eggs increase, though at what rate I am uncertain. Now the data set is read for some pivoting. Now let me do a sanity check to view the data dimensions before the pivot and then I will look at it after the pivot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 120   6\n```\n:::\n:::\n\n\nThere are four columns with the type of eggs this data set is viewing. If we want even tidier data we can collapse these four columns into one. Lets call this new data set \"eggstidy\" to represent the final form of the data in this challenge.\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggstidy <- eggs %>% \n  pivot_longer(c(3:6), names_to = \"egg_type\", values_to = \"price\")\n\neggstidy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 480 × 4\n   month     year egg_type         price\n   <chr>    <int> <chr>            <dbl>\n 1 Jan       2004 xldozen           230 \n 2 Jan       2004 xlhalf_dozen      132 \n 3 Jan       2004 large_dozen       230 \n 4 Jan       2004 large_half_dozen  126 \n 5 February  2004 xldozen           230 \n 6 February  2004 xlhalf_dozen      134.\n 7 February  2004 large_dozen       226.\n 8 February  2004 large_half_dozen  128.\n 9 March     2004 xldozen           230 \n10 March     2004 xlhalf_dozen      137 \n# … with 470 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\nFinally! After banging my head against the wall with the household data set, reading in, cleaning, and pivoting this easier data set was much more manageable. It was helpful to look at the solution to how to read in this data set, but after that, it was easy to move on my own.\n\nBy pivoting the data, each row has one observation, making it tidy for future manipulation. Within each row we can look at the particular variables within that observation with ease.\n\nBelow the dimensions have clearly changed, adding significantly more rows, but also condensing the amount of columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(eggstidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 480   4\n```\n:::\n:::\n",
    "supporting": [
      "challenge3_QuinnHe_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}